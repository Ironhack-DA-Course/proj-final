{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "#lib\n",
    "from lib.clean_scrap_functions import split_url, clean_ext_publisher, clean_repo_publisher\n",
    "# import lib.github_validator as gh_validator\n",
    "\n",
    "#Env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# os\n",
    "import os\n",
    "\n",
    "# time\n",
    "import time\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GITHUB_API_KEY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "try:\n",
    "    with open(\"../config.yaml\", \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "except:\n",
    "    print(\"Yaml configuration file not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped = pd.read_csv(config[\"data\"][\"raw\"][\"file_scraped\"])\n",
    "df_verified = pd.read_csv(config[\"data\"][\"raw\"][\"file_verified\"])\n",
    "df_vulnerable = pd.read_csv(config[\"data\"][\"raw\"][\"file_vulnerable\"])\n",
    "df_scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dimensions\n",
    "raw_files = {\"scraped\": df_scraped, \"verified\": df_verified, \"vulnerable\": df_vulnerable}\n",
    "for key, val in raw_files.items():\n",
    "        print (f\"Dimension of file '{key}': {val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total null values\n",
    "for key, val in raw_files.items():\n",
    "        print (f\"Null values of '{key}': {val.isna().sum()}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total duplicates\n",
    "for key, val in raw_files.items():\n",
    "    print(f\"{key}\")\n",
    "    for col in val.columns:\n",
    "        print (f\"Duplicated in column '{col}' of '{key}': {val[col].duplicated().sum()}\")\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check total unique values\n",
    "for key, val in raw_files.items():\n",
    "    print(f\"{key}\")\n",
    "    for col in val.columns:\n",
    "        print (f\"Total unique values in '{col}' of '{key}': {val[col].nunique()}\")\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean column names and remove columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_files = {\"scraped\": df_scraped, \"verified\": df_verified, \"vulnerable\": df_vulnerable}\n",
    "for val in raw_files.values():\n",
    "    val.columns = val.columns.str.strip().str.lower().str.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped = df_scraped.drop([\"id\", \"description\"], axis = 1).add_prefix(\"ext_\") #avoid overfitting for model training, add prefix to cols\n",
    "df_verified = df_verified.drop([\"install_count\"],axis = 1).rename(columns = {\"extension_name\":\"ext_name\", \"publisher\": \"repo_publisher\", \"source_code\":\"repository\"}) # install_count of extension in this df not updated\n",
    "df_vulnerable = df_vulnerable.drop([\"repository_name\",\"critical_vulnerability_names\", \"high_vulnerability_names\", \"medium_vulnerability_names\", \"low_vulnerability_names\"],axis = 1).rename(columns = {\"extension_name\": \"ext_name\", \"repository_link\":\"repository\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped.columns, df_verified.columns, df_vulnerable.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some dicts for cleaning\n",
    "\n",
    "duplicated_subsets = {\"scraped\": [\"ext_name\",\"ext_publisher\",\"ext_version\",\"ext_last_updated\"],\n",
    "                      \"verified\":[\"ext_name\",\"repo_publisher\",\"repository\"],\n",
    "                      \"vulnerable\": [\"ext_name\",\"repository\"],\n",
    "                     }\n",
    "\n",
    "null_subsets = {\"scraped\": [\"ext_publisher\"],\n",
    "                \"verified\": [],\n",
    "                \"vulnerable\": [\"ext_name\"],\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop duplicated after scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total duplicates\n",
    "# Check dimensions\n",
    "raw_files = {\"scraped\": df_scraped, \"verified\": df_verified, \"vulnerable\": df_vulnerable}\n",
    "for key, val in raw_files.items():\n",
    "    print(f\"{key}\")\n",
    "    for col in val.columns:\n",
    "        print (f\"Duplicated in column '{col}' of '{key}': {val[col].duplicated().sum()}\")\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped.drop_duplicates(subset=duplicated_subsets[\"scraped\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped[df_scraped[\"ext_name\"] == \"C/C++ Extension Pack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verified[df_verified[\"ext_name\"] == \"C/C++ Extension Pack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vulnerable[df_vulnerable[\"ext_name\"] == \"C/C++ Extension Pack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scraped[df_scraped.duplicated(subset=[\"name\",\"publisher\",\"version\"])]\n",
    "# df_verified[df_verified.duplicated(subset=[\"Extension Name\",\"Publisher\",\"Install Count\"])]\n",
    "# df_vulnerable[df_vulnerable.duplicated(subset=[\"Extension Name\",\"Repository Link\"])]\n",
    "df_scraped = df_scraped.drop_duplicates(subset=duplicated_subsets[\"scraped\"])\n",
    "df_verified = df_verified.drop_duplicates(subset=duplicated_subsets[\"verified\"])\n",
    "df_vulnerable = df_vulnerable.drop_duplicates(subset=duplicated_subsets[\"vulnerable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total duplicates\n",
    "# Check dimensions\n",
    "raw_files = {\"scraped\": df_scraped, \"verified\": df_verified, \"vulnerable\": df_vulnerable}\n",
    "for key, val in raw_files.items():\n",
    "    print(f\"{key}\")\n",
    "    for col in val.columns:\n",
    "        print (f\"Duplicated in column '{col}' of '{key}': {val[col].duplicated().sum()}\")\n",
    "    print()\n",
    "    print(f\"Duplicated in '{key}' with subset '{duplicated_subsets[key]}': {val.duplicated(subset= duplicated_subsets[key]).sum()} \")\n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check null values and drop null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dimensions\n",
    "raw_files = {\"scraped\": df_scraped, \"verified\": df_verified, \"vulnerable\": df_vulnerable}\n",
    "for key, val in raw_files.items():\n",
    "        print (f\"Dimension of file '{key}': {val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total null values\n",
    "raw_files = {\"scraped\": df_scraped, \"verified\": df_verified, \"vulnerable\": df_vulnerable}\n",
    "for key, val in raw_files.items():\n",
    "        print (f\"Null values of '{key}': {val.isna().sum()}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped = df_scraped.dropna(subset=null_subsets[\"scraped\"], how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not to drop null values in repository.It can be derived by ext_name, repo_publisher. Will look after it after merging  (to be done) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_verified[~((df_verified[\"repository\"].str.contains(\"https://git|https://www.git|github.com\",na=False,regex=True)) | (df_verified[\"repository\"].isna()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vulnerable = df_vulnerable[~df_vulnerable[\"ext_name\"].isna()]\n",
    "df_vulnerable = df_vulnerable.dropna(subset= null_subsets[\"vulnerable\"], how= \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vulnerable.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map value in ext_publisher vs repo_publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped[\"ext_publisher\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verified[\"repo_publisher\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped[\"merge_publisher\"] = df_scraped[\"ext_publisher\"].apply(clean_ext_publisher)\n",
    "df_verified[\"merge_publisher\"] = df_verified[\"repo_publisher\"].apply(clean_repo_publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped[\"ext_publisher\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine raw df after cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vulnerable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scraped = df_scraped[df_scraped[\"ext_rating\"]>0]\n",
    "df_ver_vul = pd.merge(df_verified,df_vulnerable, on= [\"ext_name\", \"repository\"], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ver_vul.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_verified[df_verified[\"ext_name\"] == \"C/C++ Extension Pack\"]\n",
    "# df_vulnerable[df_vulnerable[\"ext_name\"] == \"C/C++ Extension Pack\"]\n",
    "# df_ver_vul[df_ver_vul[\"ext_name\"] == \"C/C++ Extension Pack\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.merge(df_scraped, df_ver_vul, left_on=[\"ext_name\",\"merge_publisher\"], right_on=[\"ext_name\",\"merge_publisher\"], how= \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scraped[df_scraped [\"ext_name\"] == \"C/C++ Extension Pack\"]\n",
    "# df_ver_vul[df_ver_vul [\"ext_name\"] == \"C/C++ Extension Pack\"]\n",
    "# df_clean[df_clean [\"ext_name\"] == \"C/C++ Extension Pack\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Git Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[((df_clean[\"repository\"].str.contains(\"https://git|https://www.git|github.com\",na=False,regex=True)) | (df_clean[\"repository\"].isna()))]\n",
    "df_clean[\"repository\"] = df_clean[\"repository\"].apply(split_url)\n",
    "df_clean.to_csv(config[\"data\"][\"clean\"][\"file_scrap_cleaned\"],index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df_clean[((df_clean[\"repository\"].str.contains(\"https://git|https://www.git|github.com\",na=False,regex=True)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[df_clean[\"repository\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(config[\"data\"][\"raw\"][\"file_ext_repo\"])\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrap_cleaned -> repos_full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
