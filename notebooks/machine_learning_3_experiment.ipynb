{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-5rP-NER7E4",
        "outputId": "d5725133-4e36-44ca-c876-72363550dd77"
      },
      "outputs": [],
      "source": [
        "# Data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as ticker\n",
        "import graphviz\n",
        "import optuna\n",
        "import optuna.visualization as vis\n",
        "%matplotlib inline\n",
        "\n",
        "# Stats\n",
        "from statsmodels.graphics.gofplots import qqplot\n",
        "import statsmodels.api as sm\n",
        "import scipy.stats as st\n",
        "from scipy.stats import shapiro, norm, chi2_contingency, kstest, boxcox\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder,PowerTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.inspection import permutation_importance\n",
        "# Models\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import export_graphviz, DecisionTreeClassifier\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import  make_scorer, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix, classification_report #Classifier\n",
        "# from sklearn.inspection import \n",
        "\n",
        "\n",
        "from typing import Any, Optional\n",
        "\n",
        "#lib\n",
        "from lib.ml_functions_experiment import bar_labels, get_feature_importance, plot_metrics_comparison, plot_confusion_matrices\n",
        "# from wordcloud import WordCloud,STOPWORDS\n",
        "from ast import literal_eval\n",
        "from collections import Counter\n",
        "\n",
        "# os\n",
        "import os\n",
        "\n",
        "import pickle\n",
        "\n",
        "# time\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "# warnings.filterwarnings(\"ignore\")    # (Optional)\n",
        "\n",
        "print(\"Project has been created with Pandas: \" ,pd. __version__,\" And with Numpy: \",np. __version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6vLaqGpR7E-"
      },
      "source": [
        "### Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ucHEFHeaR7FE"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "try:\n",
        "    with open(\"../config.yaml\", \"r\") as file:\n",
        "        config = yaml.safe_load(file)\n",
        "except:\n",
        "    print(\"Yaml configuration file not found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBhVUL4lR7FH",
        "outputId": "4c96776c-acff-4d2c-bccb-f10eea1cfd90"
      },
      "outputs": [],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZhOuvAEKR7FJ",
        "outputId": "0c0f24b6-ed3b-4901-a8d2-6d0a070573df"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(\"./extensions_eda_cleaned.csv\")\n",
        "df = pd.read_csv(config[\"data\"][\"clean\"][\"file_eda_cleaned\"])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkAniJk3R7FK"
      },
      "source": [
        "### 5. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWiNvtNFR7FL",
        "outputId": "746eabe3-423e-4771-85f8-2ae5616cb981"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw9HH6kdR7FN"
      },
      "source": [
        "- Handle duplicated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAzpxnj4R7FP",
        "outputId": "f8eb1823-5e5d-4f96-f1ad-ca4de31e47ca"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "487cQZVtR7FQ",
        "outputId": "42492814-9a3d-4b42-8e33-d78cb3cd3620"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsywOF05R7FS"
      },
      "source": [
        "- Handle missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "bA8hl6c2R7FT",
        "outputId": "af2d7e1a-da54-449f-9fa8-f6881e88b468"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhZUsOc_R7FU"
      },
      "source": [
        "- Feature transformation/Transform values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDxQqVW2R7FU"
      },
      "source": [
        "Handle categories with high cardinality -> Grouping rare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "gmCemxEVR7FV",
        "outputId": "1e003b3e-736a-41b7-e94c-90df3e3670e2"
      },
      "outputs": [],
      "source": [
        "df[\"ext_categories\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "_XyEyR7XR7FV",
        "outputId": "713f5352-2140-4f7d-cf1f-8f01a4a06ae1"
      },
      "outputs": [],
      "source": [
        "df[\"repo_languages\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xZFptq1nR7FW"
      },
      "outputs": [],
      "source": [
        "threshold_ext_categories = 0.1  # e.g., categories below 10% frequency\n",
        "value_counts_ext_categories = df[\"ext_categories\"].value_counts(normalize=True)\n",
        "rare_categories = value_counts_ext_categories[value_counts_ext_categories.values <= threshold_ext_categories].index\n",
        "\n",
        "def transform_ext_categories(x):\n",
        "    text = str(x)\n",
        "    if text == \"Other\":\n",
        "        return \"Unknown\"\n",
        "    elif text in rare_categories:\n",
        "        return \"Others\"\n",
        "    else:\n",
        "        return x\n",
        "df[\"ext_categories_grouped\"] = df[\"ext_categories\"].apply(transform_ext_categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "x9A7UtHhR7FX"
      },
      "outputs": [],
      "source": [
        "threshold_repo_languages = 0.05 # e.g., categories below 3% frequency\n",
        "value_counts_repo_languages = df[\"repo_languages\"].value_counts(normalize=True)\n",
        "rare_categories = value_counts_repo_languages[value_counts_repo_languages.values <= threshold_repo_languages].index\n",
        "\n",
        "def transform_repo_languages(x):\n",
        "    text = str(x)\n",
        "    if text  in [\"other\", \"unknown\"]:\n",
        "        return \"unknown\"\n",
        "    elif text in rare_categories:\n",
        "        return \"others\"\n",
        "    else:\n",
        "        return x\n",
        "df[\"repo_languages_grouped\"] = df[\"repo_languages\"].apply(transform_repo_languages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qpFP3AYXR7FY"
      },
      "outputs": [],
      "source": [
        "# threshold_ext_categories = 0.1  # e.g., categories below 10% frequency\n",
        "# value_counts_ext_categories = df['ext_categories'].value_counts(normalize=True)\n",
        "# rare_categories = value_counts_ext_categories[value_counts_ext_categories.values <= threshold_ext_categories].index\n",
        "# df['ext_categories_grouped'] = df['ext_categories'].apply(lambda x: 'Rest' if x in rare_categories else x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qq91viW1R7FY"
      },
      "outputs": [],
      "source": [
        "# threshold_repo_languages = 0.03  # e.g., categories below 3% frequency\n",
        "# value_counts_repo_languages = df[\"repo_languages\"].value_counts(normalize=True)\n",
        "# rare_categories = value_counts_repo_languages[value_counts_repo_languages.values <= threshold_repo_languages].index\n",
        "# df[\"repo_languages_grouped\"] = df[\"repo_languages\"].apply(lambda x: 'rest' if x in rare_categories else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "RCuOIW-BR7FZ",
        "outputId": "bb0bd628-ece0-47ee-81bf-4b0c91e288fd"
      },
      "outputs": [],
      "source": [
        "df[\"ext_categories_grouped\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "HiYCfuSXR7FZ",
        "outputId": "6c32407a-f004-460e-cb4c-39640c5771d6"
      },
      "outputs": [],
      "source": [
        "df[\"repo_languages_grouped\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "_2X3MghDR7Fa",
        "outputId": "08fd7dac-ca3f-4550-865d-b08c7fe9d548"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=[\"repo_languages\", \"ext_categories\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hu-a4peR7Fb"
      },
      "source": [
        "- Convert target to number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kNTDfErzR7Fb"
      },
      "outputs": [],
      "source": [
        "df[\"verified\"] = df[\"verified\"].map({True: 1, False:0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgrnesK6R7Fb"
      },
      "source": [
        "- Get number and category columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QKoY4wctR7Fc",
        "outputId": "28f8786c-75c4-499f-8e40-1ee5342a8c8a"
      },
      "outputs": [],
      "source": [
        "potential_categorical_from_numerical = df.select_dtypes(\"number\").loc[:, df.select_dtypes(\"number\").nunique() < 10].drop(columns=\"verified\")\n",
        "potential_categorical_from_numerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9apGU77dR7Fc"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_categorical = pd.concat([df.select_dtypes(\"object\"), potential_categorical_from_numerical], axis=1)\n",
        "df_numerical = df.select_dtypes(\"number\").drop(columns=potential_categorical_from_numerical.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO8Ul8hZR7Fd",
        "outputId": "53fabf86-a9b6-47de-f7b7-6f28ba8b033b"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nP_0o4dFR7Fd"
      },
      "outputs": [],
      "source": [
        "cols_num = df_numerical.columns.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_gHyamBR7Fe",
        "outputId": "a9aa27f5-36f6-4446-faaa-9638671de8fb"
      },
      "outputs": [],
      "source": [
        "cols_num = df_numerical.drop([\"verified\",\"total_vulners\"],axis=1).columns.to_list() #Drop 'total_vulners'\n",
        "# cols_num = df_numerical.drop([\"verified\",\"total_vulners\",\"repo_stars\"],axis=1).columns.to_list() #Drop 'total_vulners','repo_stars'\n",
        "cols_cat = df_categorical.columns.to_list()\n",
        "cols_num, cols_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rZD3-jlOYrPx"
      },
      "outputs": [],
      "source": [
        "df_corr = pd.concat([df[cols_num], df[\"verified\"]], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "aaxLvHD9Yric",
        "outputId": "fffa68bb-6ff2-474c-d4be-9f79fa61c513"
      },
      "outputs": [],
      "source": [
        "# corr=np.abs(X_train_trans.corr(method=\"pearson\"))\n",
        "corr=np.abs(df_corr.corr(method=\"pearson\"))\n",
        "\n",
        "# Set up mask for triangle representation\n",
        "mask = np.zeros_like(corr, dtype=bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(10, 10))\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "# sns.heatmap(corr, vmax=1,square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot = corr)\n",
        "sns.heatmap(corr, mask=mask,  vmax=1,square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot = corr)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjhRt8cpR7Ff"
      },
      "source": [
        "#### Spliting Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Ti08zYQiR7Ff"
      },
      "outputs": [],
      "source": [
        "features = df.drop(columns = [\"verified\",\"total_vulners\"])\n",
        "# features = df.drop([\"verified\",\"total_vulners\",\"repo_stars\"], axis = 1)\n",
        "target = df[\"verified\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(features,target, test_size = 0.20, random_state=0) #before transforming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfYGBfyRR7Fg",
        "outputId": "802ab27e-ac57-4194-8cb6-4fbd907aa027"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "JRBuRQnxR7Fh",
        "outputId": "b0d2834c-b167-49a3-fdd8-96916cccb90f"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXgvu2AVR7Fh"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9TtMqOFR7Fi"
      },
      "source": [
        "OHE: for nominal categorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PZR6zu1tR7Fi"
      },
      "outputs": [],
      "source": [
        "ohe = OneHotEncoder(sparse_output=False)\n",
        "ohe.fit((X_train[[\"repo_languages_grouped\", \"ext_categories_grouped\"]]))\n",
        "X_train_trans_nom_np = ohe.transform(X_train[[\"repo_languages_grouped\", \"ext_categories_grouped\"]])\n",
        "X_test_trans_nom_np = ohe.transform(X_test[[\"repo_languages_grouped\", \"ext_categories_grouped\"]])\n",
        "\n",
        "X_train_nom_trans_df = pd.DataFrame(X_train_trans_nom_np, columns=ohe.get_feature_names_out(), index=X_train.index)\n",
        "X_test_nom_trans_df = pd.DataFrame(X_test_trans_nom_np, columns=ohe.get_feature_names_out(), index=X_test.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "F_FjZt8HR7Fj",
        "outputId": "020775aa-3ae1-49d1-ea44-abbf7043263d"
      },
      "outputs": [],
      "source": [
        "X_train_nom_trans_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Ui8UGZy_R7Fx"
      },
      "outputs": [],
      "source": [
        "base_name = f\"X_train_{id(X_train)}_Y_train_{id(y_train)}\"\n",
        "file_path = f\"{config[\"model\"][\"preprocessing_path\"]}{base_name}_onehot_encoding.pkl\"\n",
        "\n",
        "with open(file_path, \"wb\") as file:\n",
        "    pickle.dump(ohe, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olgkq0CeR7Fx"
      },
      "source": [
        "Transform cols_num to normal distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SM_6zWlUR7Fy",
        "outputId": "ce40994a-f72b-45cb-d224-c393e06f58a2"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows = int(np.ceil(len(cols_num)/2)), ncols = 2, figsize = (8,10))\n",
        "axes = axes.flat\n",
        "\n",
        "for i,col in enumerate(cols_num):\n",
        "    sm.qqplot(X_test[col],\n",
        "           line = \"s\",\n",
        "           ax = axes[i])\n",
        "\n",
        "    axes[i].set_title(col, fontsize = 10, fontweight = \"bold\", color = \"black\")\n",
        "\n",
        "# fig.delaxes(axes[7])\n",
        "fig.suptitle(\"QQ-Plots before Transforming\", fontsize = 12, fontweight = \"bold\", color = \"darkblue\")\n",
        "fig.tight_layout()\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-MoSKEeR7Fz"
      },
      "source": [
        "Powertransform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "3xnvUIBLR7Fz"
      },
      "outputs": [],
      "source": [
        "# Power transform\n",
        "pt = PowerTransformer(method=\"yeo-johnson\")\n",
        "\n",
        "X_train_num = X_train[cols_num]\n",
        "pt.fit(X_train_num)\n",
        "X_test_num  = X_test[cols_num]\n",
        "\n",
        "X_train_num_trans = pt.transform(X_train_num)\n",
        "X_test_num_trans = pt.transform(X_test_num)\n",
        "\n",
        "X_train_num_trans_df = pd.DataFrame(X_train_num_trans, columns=X_train_num.columns, index=X_train_num.index )\n",
        "X_test_num_trans_df = pd.DataFrame(X_test_num_trans, columns=X_test_num.columns, index=X_test_num.index )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_name = f\"X_train_{id(X_train)}_Y_train_{id(y_train)}\"\n",
        "file_path = f\"{config[\"model\"][\"preprocessing_path\"]}{base_name}_power_transformer.pkl\"\n",
        "\n",
        "with open(file_path, \"wb\") as file:\n",
        "    pickle.dump(pt, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB5DuL-CR7F0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFhD7NEiR7F0"
      },
      "source": [
        "Normalize transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "bwEFv1-pR7F1"
      },
      "outputs": [],
      "source": [
        "# #Normalizer\n",
        "# normalizer = MinMaxScaler()\n",
        "# X_train_num = X_train[cols_num]\n",
        "# normalizer.fit(X_train_num)\n",
        "# X_test_num  = X_test[cols_num]\n",
        "\n",
        "# X_train_trans = normalizer.transform(X_train_num)\n",
        "# X_test_trans = normalizer.transform(X_test_num)\n",
        "\n",
        "# X_train_trans = pd.DataFrame(X_train_trans, columns=X_train_num.columns, index=X_train_num.index)\n",
        "# X_test_trans = pd.DataFrame(X_test_trans, columns=X_test_num.columns, index=X_test_num.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0qG7TCCR7F1"
      },
      "source": [
        "Log Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "BWCM4b5VR7F2"
      },
      "outputs": [],
      "source": [
        "# #Log-transform\n",
        "# for col in cols_num:\n",
        "#     df[col] = np.log1p(df[col])\n",
        "    # X_train_trans = pt.transform(X_train_num)\n",
        "    # X_test_trans = pt.transform(X_test_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JjbZJdNKR7F2",
        "outputId": "aae0545b-5506-41f5-9178-1b8e9bd17ec6"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows = int(np.ceil(len(cols_num)/2)), ncols = 2, figsize = (8,10))\n",
        "axes = axes.flat\n",
        "\n",
        "for i,col in enumerate(cols_num):\n",
        "    # sns.histplot(X_test_num_trans_df[col],\n",
        "    #              kde=True,\n",
        "    #              bins=20,\n",
        "    #              color=\"orange\",\n",
        "    #              ax=axes[i])\n",
        "\n",
        "    sm.qqplot(X_test_num_trans_df[col],\n",
        "           line = \"s\",\n",
        "           ax = axes[i]);\n",
        "\n",
        "    axes[i].set_title(col, fontsize = 10, fontweight = \"bold\", color = \"black\")\n",
        "\n",
        "# fig.delaxes(axes[7])\n",
        "fig.suptitle(\"QQ-Plots after Transforming\", fontsize = 12, fontweight = \"bold\", color = \"darkblue\")\n",
        "fig.tight_layout()\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CjrZlXBR7F3"
      },
      "source": [
        "Combining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Ic2K0O_6R7F4"
      },
      "outputs": [],
      "source": [
        "X_train_ord_trans_df = X_train[[\"ext_rating_category\",\"ext_version_category\"]].copy()\n",
        "X_test_ord_trans_df = X_test[[\"ext_rating_category\",\"ext_version_category\"]].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "XlPTwJtvR7F5"
      },
      "outputs": [],
      "source": [
        "X_train_trans = pd.concat([X_train_num_trans_df, X_train_nom_trans_df, X_train_ord_trans_df], axis=1)\n",
        "X_test_trans = pd.concat([X_test_num_trans_df, X_test_nom_trans_df, X_test_ord_trans_df], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "wW8rHZ7mR7F6"
      },
      "outputs": [],
      "source": [
        "X_trans =  pd.concat([X_train_trans, X_test_trans], axis = 0)\n",
        "y_trans = pd.concat([y_train, y_test], axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "buGiubd1R7F6",
        "outputId": "a106bb77-843b-43f2-f7a1-50538c590c79"
      },
      "outputs": [],
      "source": [
        "df_trans = pd.concat([X_trans,y_trans], axis = 1)\n",
        "df_trans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "PaBSUm0dR7F7"
      },
      "outputs": [],
      "source": [
        "# X_train_trans.shape[0] == X_train.shape[0]\n",
        "# X_test_trans.shape[0] == X_test.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "AT-AgkTyR7F8"
      },
      "outputs": [],
      "source": [
        "# X_train_corr = pd.concat([X_train_trans, y_train], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a-H2bvZR7F8"
      },
      "source": [
        "Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YGWy39mxR7F9",
        "outputId": "021a7714-646a-458b-ab9e-be28e7f6b356"
      },
      "outputs": [],
      "source": [
        "# corr=np.abs(X_train_trans.corr(method=\"pearson\"))\n",
        "corr=np.abs(df_trans.corr(method=\"pearson\"))\n",
        "\n",
        "# Set up mask for triangle representation\n",
        "mask = np.zeros_like(corr, dtype=bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(10, 10))\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "# sns.heatmap(corr, vmax=1,square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot = corr)\n",
        "sns.heatmap(corr, mask=mask,  vmax=1,square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot = corr)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHy7QPIbR7F-"
      },
      "source": [
        "**_We want low correlation between features, but high correlation between features and our target._**\n",
        "\n",
        "There are high correlations between **_repo stars vs repo forks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "UFdSx5DMR7F_"
      },
      "outputs": [],
      "source": [
        "# features_ = df_trans.drop(columns = [\"verified\"])\n",
        "# target_ = df_trans[\"verified\"]\n",
        "# Xtrans_train, Xtrans_test, ytrans_train, ytrans_test = train_test_split(features,target, test_size = 0.20, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsDX6Yn3R7GA"
      },
      "source": [
        "#### Imbalanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "_bbKIFU1R7GB"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(random_state = 1,sampling_strategy=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "GFPYwhAlR7GB"
      },
      "outputs": [],
      "source": [
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_trans, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "EJSj5eQJWDaG",
        "outputId": "3c7317bc-d4d6-4fda-cae5-ce46bfbad699"
      },
      "outputs": [],
      "source": [
        "X_train_smote"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA1TC5z1Gin9"
      },
      "source": [
        "|Metric|Definition|\tMeaning in Attrition Context|\n",
        "| ----------- | ----------- | ----------- |\n",
        "| Recall|  TP/(TP+FN) | \tMost important – how many true leavers you can catch|\n",
        "| Precision\t |TP/(TP+FP) |\tAmong predicted leavers, how many are actually correct\n",
        "Accuracy |(TP+TN)/Total |\tCan be misleading with imbalanced data (e.g., <20% attrition) |\n",
        "| F1-score |2⋅Precision⋅Recall/(Precision+Recall) |Balanced trade-off between Precision and Recall|\n",
        "| AUC-ROC\t|Area under ROC Curve |\tMeasures ability to distinguish leavers vs. stayers at all thresholds|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Training + Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "hg5a3rYUTtqG"
      },
      "outputs": [],
      "source": [
        "# Code optimized metrics, plots\n",
        "def training_classification_optimized(x_train, x_test, y_train, y_test, save_models=True):\n",
        "    '''Train and evaluate multiple classifiers with comprehensive metrics'''\n",
        "\n",
        "    # Define models dictionary\n",
        "    models = {\n",
        "        #Ensemble\n",
        "        \"Random Forest\": RandomForestClassifier(random_state=0),\n",
        "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=0),\n",
        "\n",
        "        #Ensemble, should Not be used as standalone?!!\n",
        "        \"Bagging Classifier\": BaggingClassifier(random_state=0), #default use with DecisionTreeClassifier\n",
        "        \"Ada Boost\": AdaBoostClassifier(random_state=0), #default use with DecisionTreeClassifier\n",
        "\n",
        "        #Trees\n",
        "        \"Extra Trees\": ExtraTreesClassifier(random_state=0),\n",
        "        \"Decision Trees\": DecisionTreeClassifier(random_state=0),\n",
        "        \"XGBoost\": XGBClassifier(random_state=0, eval_metric=\"logloss\"),\n",
        "        \"LightGBM\": LGBMClassifier(verbose=-1, random_state=0),\n",
        "        \"CatBoost\": CatBoostClassifier(verbose=False, random_state=0),\n",
        "\n",
        "        #Linear\n",
        "        \"Logistic Regression\": LogisticRegression(random_state=0, max_iter=1000),\n",
        "\n",
        "        #Probabilistic Models\n",
        "        # \"ComplementNB\": ComplementNB(),#Negative values\n",
        "        # \"MultinomialNB\": MultinomialNB(),#Negative values\n",
        "        \"BernoulliNB\" : BernoulliNB(),\n",
        "        \"GaussianNB\": GaussianNB(), \n",
        "\n",
        "        #Kernel-Based Models\n",
        "        \"SVC\": SVC(random_state=0, probability=True),  # Added probability=True for ROC-AUC , slow execution\n",
        "\n",
        "        #Instance-Based\n",
        "        \"KNN\": KNeighborsClassifier(),\n",
        "\n",
        "    }\n",
        "\n",
        "    # Define metrics to calculate\n",
        "    metrics = {\n",
        "        \"Accuracy\": {},\n",
        "        \"Precision\": {},\n",
        "        \"Recall\": {},\n",
        "        \"F1_Score\": {},\n",
        "        \"ROC_AUC\": {}\n",
        "    }\n",
        "\n",
        "    cms = {}\n",
        "    reports = {}\n",
        "    importances = {}\n",
        "\n",
        "    print(\"Training models...\")\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    for name, model in models.items():\n",
        "        print(f\"Training {name}...\")\n",
        "        model.fit(x_train, y_train)\n",
        "\n",
        "        base_name = f\"X_train_{id(x_train)}_Y_train_{id(y_train)}\"\n",
        "        file_path = f\"{config[\"model\"][\"training_path\"]}{base_name}_{name.replace(' ', '_')}.pkl\"\n",
        "        # file_path = f\"{base_name}_{name.replace(' ', '_')}.pkl\"\n",
        "        # Save model if requested\n",
        "        if save_models:\n",
        "            # with open(f\"{config[\"model\"][\"training_path\"]}{name.replace(' ', '_')}.pkl\", \"wb\") as file:\n",
        "            with open(file_path, \"wb\") as file:\n",
        "                pickle.dump(model, file)\n",
        "\n",
        "        y_pred = model.predict(x_test)\n",
        "\n",
        "        # Get probabilities for ROC-AUC (handle models without predict_proba)\n",
        "        try:\n",
        "            y_proba = model.predict_proba(x_test)[:, 1]\n",
        "        except AttributeError:\n",
        "            y_proba = y_pred  # Fallback for models without probability prediction\n",
        "\n",
        "        # Calculate metrics\n",
        "        metrics[\"Accuracy\"][name] = accuracy_score(y_test, y_pred) * 100\n",
        "        metrics[\"Precision\"][name] = precision_score(y_test, y_pred, average=\"binary\") * 100\n",
        "        metrics[\"Recall\"][name] = recall_score(y_test, y_pred, average=\"binary\") * 100\n",
        "        metrics[\"F1_Score\"][name] = f1_score(y_test, y_pred, average=\"binary\") * 100\n",
        "\n",
        "        try:\n",
        "            metrics[\"ROC_AUC\"][name] = roc_auc_score(y_test, y_proba) * 100\n",
        "        except ValueError:\n",
        "            metrics[\"ROC_AUC\"][name] = 0  # Handle cases where ROC-AUC can't be calculated\n",
        "\n",
        "        # Store confusion matrix and classification report\n",
        "        cms[name] = confusion_matrix(y_test, y_pred)\n",
        "        reports[name] = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "        # Get feature importance\n",
        "        importances[name] = get_feature_importance(model, x_test, y_test, method=\"auto\", top_n=5)\n",
        "\n",
        "    # Create comprehensive results DataFrame\n",
        "    selected_metric = \"Recall\"\n",
        "    results_df = pd.DataFrame(metrics).round(2)\n",
        "    results_df = results_df.sort_values(selected_metric, ascending=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"OVERALL RESULTS SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "    print(results_df)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"INDIVIDUAL METRICS\")\n",
        "    print(\"=\"*50)\n",
        "    metric_names = list(metrics.keys())\n",
        "    plot_metrics_comparison(metrics, metric_names)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"CONFUSION MATRICES OF '{selected_metric.upper()}'\")\n",
        "    print(\"=\"*50)\n",
        "    plot_confusion_matrices(cms, results_df, metric_for_title=selected_metric)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"CLASSIFICATION REPORTS\")\n",
        "    print(\"=\"*50)\n",
        "    for name in results_df.index:\n",
        "        print(f\"\\n{'*'*30}\\n{name}\\n{'*'*30}\")\n",
        "        report_df = pd.DataFrame(reports[name]).transpose().round(2)\n",
        "        print(report_df)\n",
        "\n",
        "    # Return results for further analysis\n",
        "    # return {\n",
        "    #     'metrics': metrics,\n",
        "    #     'results_df': results_df,\n",
        "    #     'confusion_matrices': cms,\n",
        "    #     'classification_reports': reports,\n",
        "    #     'feature_importances': importances,\n",
        "    #     'models': models\n",
        "    # }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8pkg3o4wnY6y",
        "outputId": "8863e457-0dae-457c-c01c-b87ca0f3eee0"
      },
      "outputs": [],
      "source": [
        "training_classification_optimized(X_train_trans, X_test_trans, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD_tuh2HiJBM"
      },
      "outputs": [],
      "source": [
        "training_classification_optimized(X_train_smote, X_test_trans, y_train_smote, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insight:\n",
        "- Bagging (with DecisionTree) gives the best prediction in term of Recall, F1 on imbalanced and balanced dataset\n",
        "- SVC Model takes a lot of computational and time -> Less effective\n",
        "- SMOTE balancing improves significantly performances of weak models imbalanced data\n",
        "- Extension\\_install\\_count is an important feature which afffects the prediction of breached extension. In combination with high repo_stars or/and repo_forks, the extension has a high proability of being breached"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Best model was Bagging, we gonna use hyperparam + crossvalidation to tune the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHYxzWCaJ-MT"
      },
      "outputs": [],
      "source": [
        "#GridSearch OPtimized\n",
        "\n",
        "# Define parameter grid for BaggingClassifier\n",
        "param_grid_bag = {\n",
        "    'bootstrap': [True, False],\n",
        "    'bootstrap_features': [True, False],    \n",
        "    'n_estimators': [5, 10],\n",
        "    'max_samples': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize BaggingClassifier\n",
        "bag = BaggingClassifier(random_state=123)\n",
        "\n",
        "# Set confidence level and number of folds\n",
        "confidence_level = 0.95\n",
        "folds = 10\n",
        "\n",
        "# Define recall scoring metric\n",
        "recall_scoring = make_scorer(recall_score)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "gs = GridSearchCV(\n",
        "    estimator=bag,\n",
        "    param_grid=param_grid_bag,\n",
        "    scoring=recall_scoring,\n",
        "    cv=folds,\n",
        "    verbose=10\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV and measure time\n",
        "start_time = time.time()\n",
        "gs.fit(X_train_trans, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "# Print time taken\n",
        "print(f\"\\nTime taken to find the best combination of hyperparameters: {end_time - start_time:.4f} seconds\\n\")\n",
        "\n",
        "# Extract results into a DataFrame and sort by mean test score\n",
        "results_gs_df = pd.DataFrame(gs.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
        "\n",
        "# Calculate confidence interval for the best model's recall score\n",
        "gs_mean_score = results_gs_df.iloc[0][\"mean_test_score\"]\n",
        "gs_sem = results_gs_df.iloc[0][\"std_test_score\"] / np.sqrt(folds)\n",
        "gs_tc = st.t.ppf(1 - ((1 - confidence_level) / 2), df=folds - 1)\n",
        "gs_lower_bound = gs_mean_score - (gs_tc * gs_sem)\n",
        "gs_upper_bound = gs_mean_score + (gs_tc * gs_sem)\n",
        "\n",
        "# Print best recall score and confidence interval\n",
        "print(f\"Best recall score for training data: {gs.best_score_:.4f}\")\n",
        "print(f\"Recall confidence interval for best hyperparameters: ({gs_lower_bound:.4f}, {gs_upper_bound:.4f})\\n\")\n",
        "\n",
        "# Get the best model\n",
        "best_model = gs.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "y_pred_train = best_model.predict(X_train_trans)\n",
        "y_pred_test = best_model.predict(X_test_trans)\n",
        "\n",
        "# Evaluate performance on test data\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
        "print(f\"Test Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
        "print(f\"Test Recall: {recall_score(y_test, y_pred_test):.4f}\")\n",
        "print(f\"Test F1: {f1_score(y_test, y_pred_test):.4f}\\n\")\n",
        "\n",
        "# Print best hyperparameters and test recall score\n",
        "print(f\"Best combination of hyperparameters: {gs.best_params_}\")\n",
        "print(f\"Recall score for test data: {recall_score(y_test, y_pred_test):.4f}\")\n",
        "# print(f\"Best combi's score for Test_data:  {best_model.score(X_test_trans, y_test): .4f} # Always sign to accuracy_score in GridScearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- RandomizedSeachCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameter_grid_dct = {\"max_depth\": [10, 50],\n",
        "#                   \"min_samples_split\": [4, 16],\n",
        "#                   \"max_leaf_nodes\": [250, 1000],\n",
        "#                   \"max_features\": [\"sqrt\", \"log2\"]}\n",
        "\n",
        "param_grid_bag = {\n",
        " 'bootstrap': [True, False],\n",
        " 'bootstrap_features': [True, False],    \n",
        " 'n_estimators': [5, 10],\n",
        " 'max_samples' : [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "folds= 10\n",
        "\n",
        "# dt = DecisionTreeClassifier(random_state=123)\n",
        "bag = BaggingClassifier(random_state = 123)\n",
        "\n",
        "recall_scoring = make_scorer(recall_score)\n",
        "# precision_scoring = make_scorer(precision_score)\n",
        "\n",
        "# rs = RandomizedSearchCV(dt, param_distributions = parameter_grid, n_iter = 16, cv = folds, verbose=10, random_state=123)\n",
        "rs = RandomizedSearchCV(bag, param_distributions = param_grid_bag, scoring=recall_scoring, n_iter = 16, cv = folds, verbose=10, random_state=123)\n",
        "\n",
        "start_time = time.time()\n",
        "rs.fit(X_train_trans, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"Time taken to find the best combination of hyperparameters among the given ones: {end_time - start_time: .4f} seconds\")\n",
        "print(\"\\n\")\n",
        "\n",
        "results_rs_df = pd.DataFrame(rs.cv_results_).sort_values(by=\"mean_test_score\", ascending=False)\n",
        "\n",
        "rs_mean_score = results_rs_df.iloc[0,-3]\n",
        "rs_sem = results_rs_df.iloc[0,-2] / np.sqrt(10)\n",
        "\n",
        "rs_tc = st.t.ppf(1-((1-confidence_level)/2), df=folds-1)\n",
        "rs_lower_bound = rs_mean_score - ( rs_tc * gs_sem )\n",
        "rs_upper_bound = rs_mean_score + ( rs_tc * gs_sem )\n",
        "\n",
        "print(f\"The best score 'Recall' for Train_data is: {gs.best_score_: .4f}\")\n",
        "print(f\"The confidence interval for the best combination of hyperparameters is: \\\n",
        "    ({rs_lower_bound: .4f}, {rs_mean_score: .4f}, {rs_upper_bound: .4f}) \")\n",
        "\n",
        "\n",
        "best_model = rs.best_estimator_\n",
        "\n",
        "y_pred_train_df = best_model.predict(X_train_trans)\n",
        "# y_pred_train_df = best_model.predict(X_train_smote)\n",
        "y_pred_test_df  = best_model.predict(X_test_trans)\n",
        "\n",
        "print(\"\\n\")\n",
        "# print(f\"Test Accuracy: {accuracy_score(y_pred_test_df, y_test): .4f}\")\n",
        "print(f\"Best combi's  score:  {best_model.score(X_test_trans, y_test): .4f}\")\n",
        "print(f\"Test Prec: {precision_score(y_pred_test_df, y_test): .4f}\")\n",
        "print(f\"Test Recall: {recall_score(y_pred_test_df, y_test): .4f}\")\n",
        "print(f\"Test F1: {f1_score(y_pred_test_df, y_test): .4f}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(f\"Test Recall: {recall_score(y_pred_test_df, y_test): .4f}\")\n",
        "print(f\"The best combination of hyperparameters has been: {gs.best_params_}\")\n",
        "# print(f\"Best combi's Recall score for Test_data:  {best_model.score(X_test_trans, y_test): .4f}\") #Always sign to accuracy_score in RandomSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Bayesian Search + Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective(trial, confidence_level, folds):\n",
        "\n",
        "    # First, we define the grid with values to consider when train several possible combinations.\n",
        "    # Now we specify a range/list of values to try for each hyper-parameter, and we let optuna to decide which\n",
        "    # combination to try.\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 10, 50) # trial.suggest_int(\"hyperparameter_name\", min_value, maximum_value)\n",
        "    min_samples_split = trial.suggest_int(\"min_samples_split\", 4, 16)\n",
        "    max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\", 250, 1000)\n",
        "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"])\n",
        "    recall_scoring = make_scorer(recall_score, response_method='predict')\n",
        "\n",
        "    dt = DecisionTreeClassifier(random_state=123,\n",
        "                               max_depth=max_depth,\n",
        "                               min_samples_split=min_samples_split,\n",
        "                               max_leaf_nodes=max_leaf_nodes,\n",
        "                               max_features=max_features)\n",
        "\n",
        "    # Here the parameter \"cv\" specifies the number of folds K\n",
        "    scores = cross_val_score(dt, X_train_trans, y_train,scoring=recall_scoring, cv=folds) # The scores provided will be the score on each hold out fold\n",
        "    mean_score = np.mean(scores)\n",
        "    sem = np.std(scores, ddof=1) / np.sqrt(folds)\n",
        "\n",
        "    tc = st.t.ppf(1-((1-confidence_level)/2), df=folds-1)\n",
        "    lower_bound = mean_score - ( tc * sem )\n",
        "    upper_bound = mean_score + ( tc * sem )\n",
        "\n",
        "    # Here, we're storing confidence interval for each trial. It's not possible for the objective function to return\n",
        "    # multiple values as Optuna uses the only returned value to find the best combination of hyperparameters.\n",
        "    trial.set_user_attr(\"CV_score_summary\", [round(lower_bound,4), round(np.mean(scores),4), round(upper_bound,4)])\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "confidence_level = 0.95\n",
        "folds = 10\n",
        "\n",
        "start_time = time.time()\n",
        "study = optuna.create_study(direction=\"maximize\") # We want to have the maximum values for the scores\n",
        "study.optimize(lambda trial: objective(trial, confidence_level, folds), n_trials=45)\n",
        "#study.optimize(objective(**settings), n_trials=45) # n_trials is the number of combinations of hyperparameters to test.\n",
        "end_time = time.time()\n",
        "best_model = study.best_params\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"Time taken to find the best combination of hyperparameters among the given ones: {end_time - start_time: .4f} seconds\")\n",
        "print(f\"The best score found was: {study.best_value: .4f}\")\n",
        "\n",
        "\n",
        "best_model = DecisionTreeClassifier(random_state=123, **study.best_params)\n",
        "best_model.fit(X_train_trans, y_train)\n",
        "# best_model.fit(X_train_smote, y_train_smote)\n",
        "y_pred_test_df = best_model.predict(X_test_trans)\n",
        "\n",
        "print(f\"Test Acc: {accuracy_score(y_pred_test_df, y_test): .3f}\")\n",
        "print(f\"Test Pre: {precision_score(y_pred_test_df, y_test): .3f}\")\n",
        "print(f\"Test Recall: {recall_score(y_pred_test_df, y_test): .3f}\")\n",
        "print(f\"Test F1: {f1_score(y_pred_test_df, y_test): .3f}\")\n",
        "\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"Best combi's  score:  {best_model.score(X_test_trans, y_test): .3f}\")\n",
        "print(f\"The best combination of hyperparameters found was: {best_model}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "GridSearchCV\n",
        "    Time taken to find the best combination of hyperparameters: 760.6650 seconds\n",
        "\n",
        "    Best recall score for training data: 0.7562\n",
        "    Recall confidence interval for best hyperparameters: (0.7357, 0.7767)\n",
        "\n",
        "    Test Accuracy: 0.9688\n",
        "    Test Precision: 0.9398\n",
        "    Test Recall: 0.7545\n",
        "    Test F1: 0.8370\n",
        "\n",
        "    Best combination of hyperparameters: {'bootstrap': False, 'bootstrap_features': True, 'max_samples': 1.0, 'n_estimators': 10}\n",
        "    Recall score for test data: 0.7545"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45SG7fnRR7GF"
      },
      "source": [
        "- 🌲 Random Forest\n",
        "\n",
        "Ensemble of decision trees (bagging).\n",
        "Uses random subsets of data and features.\n",
        "Robust to overfitting and outliers.\n",
        "Good baseline model for tabular data.\n",
        "- ⚡ AdaBoost\n",
        "\n",
        "Sequential boosting of weak learners.\n",
        "Focuses on previous misclassified samples.\n",
        "Sensitive to noise/outliers.\n",
        "Good for clean data with subtle patterns.\n",
        "- 🚀 XGBoost\n",
        "\n",
        "Optimized gradient boosting algorithm.\n",
        "Fast, accurate, and regularized.\n",
        "Best for performance with tuning effort.\n",
        "\n",
        "- 📊 Logistic Regression\n",
        "\n",
        "Linear model for binary classification.\n",
        "Estimates probabilities using a sigmoid function.\n",
        "Assumes a linear relationship between features and the log-odds of the target.\n",
        "Simple, fast, and interpretable — great baseline for linearly separable data.\n",
        "\n",
        "- 🎯 Support Vector Machine (SVM)\n",
        "\n",
        "Finds the optimal hyperplane that maximizes the margin between classes.\n",
        "Works well in high-dimensional spaces.\n",
        "Can use different kernels (linear, RBF, polynomial) to capture nonlinear patterns.\n",
        "Sensitive to scaling; may be slower on large datasets.\n",
        "\n",
        "- 👟 K-Nearest Neighbors (KNN)\n",
        "\n",
        "Instance-based learning — no training, just storing.\n",
        "Classifies based on the majority label among k-nearest neighbors.\n",
        "Simple and intuitive, but slow with large datasets.\n",
        "Sensitive to feature scaling and irrelevant features."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dev-python-312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
